{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from tensorflow.python.ops import lookup_ops\n",
    "from tensorflow.python.training.tracking import tracking\n",
    "\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import os\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, LSTM,Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout,GlobalMaxPooling1D,GlobalAveragePooling1D,concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelEncoder(Model):\n",
    "    def __init__(self,state_size,n_layers):\n",
    "        super(LanguageModelEncoder, self).__init__()\n",
    "        self._state_size = state_size\n",
    "        self._lstm_layers = [LSTM(self._state_size,return_sequences=True) for i in range(n_layers)]\n",
    "        #self._lstm_layer = tf.keras.layers.LSTM(state_size,return_sequences=True)\n",
    "        \n",
    "    def __call__(self,sentence_embeddings):\n",
    "        \n",
    "        lstm_output = sentence_embeddings # initialize to the input\n",
    "        for lstm_layer in self._lstm_layers:\n",
    "            lstm_output = lstm_layer(lstm_output)\n",
    "        #lstm_output = self._lstm_layer(sentence_embeddings)\n",
    "        return lstm_output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocabulary_file(vocabulary):\n",
    "  \"\"\"Write temporary vocab file for module construction.\"\"\"\n",
    "  tmpdir = tempfile.mkdtemp()\n",
    "  vocabulary_file = os.path.join(tmpdir, \"tokens.txt\")\n",
    "  with tf.io.gfile.GFile(vocabulary_file, \"w\") as f:\n",
    "    for entry in vocabulary:\n",
    "      f.write(entry + \"\\n\")\n",
    "  return vocabulary_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ULMFiTModule(tf.train.Checkpoint):\n",
    "  \"\"\"\n",
    "  LATER \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, vocab, emb_dim, buckets, state_size,n_layers):\n",
    "    super(ULMFiTModule, self).__init__()\n",
    "    self._buckets = buckets\n",
    "    self._vocab_size = len(vocab)\n",
    "    self.emb_row_size = self._vocab_size+self._buckets\n",
    "    self._embeddings = tf.Variable(tf.random.uniform(shape=[self.emb_row_size, emb_dim]))\n",
    "    self._state_size = state_size\n",
    "    self.model = LanguageModelEncoder(state_size,n_layers)\n",
    "    self._vocabulary_file = tracking.TrackableAsset(write_vocabulary_file(vocab)) \n",
    "    self.w2i_table = lookup_ops.index_table_from_file(\n",
    "                    vocabulary_file= self._vocabulary_file,\n",
    "                    num_oov_buckets=self._buckets,\n",
    "                    hasher_spec=lookup_ops.FastHashSpec)\n",
    "    self.i2w_table = lookup_ops.index_to_string_table_from_file(\n",
    "                    vocabulary_file=self._vocabulary_file, \n",
    "                    delimiter = '\\n',\n",
    "                    default_value=\"UNKNOWN\")\n",
    "    self._logit_layer = tf.keras.layers.Dense(self.emb_row_size)\n",
    "\n",
    "\n",
    "    \n",
    "  def _tokenize(self, sentences):\n",
    "    # Perform a minimalistic text preprocessing by removing punctuation and\n",
    "    # splitting on spaces.\n",
    "    normalized_sentences = tf.strings.regex_replace(\n",
    "        input=sentences, pattern=r\"\\pP\", rewrite=\"\")\n",
    "    sparse_tokens = tf.strings.split(normalized_sentences, \" \").to_sparse()\n",
    "\n",
    "    # Deal with a corner case: there is one empty sentence.\n",
    "    sparse_tokens, _ = tf.sparse.fill_empty_rows(sparse_tokens, tf.constant(\"\"))\n",
    "    # Deal with a corner case: all sentences are empty.\n",
    "    sparse_tokens = tf.sparse.reset_shape(sparse_tokens)\n",
    "\n",
    "    return (sparse_tokens.indices, sparse_tokens.values,\n",
    "            sparse_tokens.dense_shape)\n",
    "    \n",
    "  def _indices_to_words(self, indices):\n",
    "    #return tf.gather(self._vocab_tensor, indices)\n",
    "    return self.i2w_table.lookup(indices)\n",
    "    \n",
    "\n",
    "  def _words_to_indices(self, words):\n",
    "    #return tf.strings.to_hash_bucket(words, self._buckets)\n",
    "    return self.w2i_table.lookup(words)\n",
    "  \n",
    "  @tf.function(input_signature=[tf.TensorSpec([None],tf.dtypes.string)])   \n",
    "  def _tokens_to_lookup_ids(self,sentences):\n",
    "    token_ids, token_values, token_dense_shape = self._tokenize(sentences)\n",
    "    tokens_sparse = tf.sparse.SparseTensor(\n",
    "        indices=token_ids, values=token_values, dense_shape=token_dense_shape)\n",
    "    tokens = tf.sparse.to_dense(tokens_sparse, default_value=\"\")\n",
    "\n",
    "    sparse_lookup_ids = tf.sparse.SparseTensor(\n",
    "        indices=tokens_sparse.indices,\n",
    "        values=self._words_to_indices(tokens_sparse.values),\n",
    "        dense_shape=tokens_sparse.dense_shape)\n",
    "    lookup_ids = tf.sparse.to_dense(sparse_lookup_ids, default_value=0)\n",
    "    return tokens,lookup_ids\n",
    "        \n",
    "    \n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec([None], tf.dtypes.string)])\n",
    "  def train(self, sentences,validation_sentences=None):\n",
    "    tokens,lookup_ids = self._tokens_to_lookup_ids(sentences)\n",
    "    # Targets are the next word for each word of the sentence.\n",
    "    tokens_ids_seq = lookup_ids[:, 0:-1]\n",
    "    tokens_ids_target = lookup_ids[:, 1:]\n",
    "    tokens_prefix = tokens[:, 0:-1]\n",
    "\n",
    "    # Mask determining which positions we care about for a loss: all positions\n",
    "    # that have a valid non-terminal token.\n",
    "    mask = tf.logical_and(\n",
    "        tf.logical_not(tf.equal(tokens_prefix, \"\")),\n",
    "        tf.logical_not(tf.equal(tokens_prefix, \"<E>\")))\n",
    "\n",
    "    input_mask = tf.cast(mask, tf.int32)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "      sentence_embeddings = tf.nn.embedding_lookup(self._embeddings,\n",
    "                                                   tokens_ids_seq)\n",
    "    \n",
    "      lstm_output = self.model(sentence_embeddings)\n",
    "      lstm_output = tf.reshape(lstm_output, [-1,self._state_size])\n",
    "      logits = self._logit_layer(lstm_output)\n",
    "      \n",
    "\n",
    "      targets = tf.reshape(tokens_ids_target, [-1])\n",
    "      weights = tf.cast(tf.reshape(input_mask, [-1]), tf.float32)\n",
    "\n",
    "      losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          labels=targets, logits=logits)\n",
    "\n",
    "      # Final loss is the mean loss for all token losses.\n",
    "      final_loss = tf.math.divide(\n",
    "          tf.reduce_sum(tf.multiply(losses, weights)),\n",
    "          tf.reduce_sum(weights),\n",
    "          name=\"final_loss\")\n",
    "\n",
    "    watched = t.watched_variables()\n",
    "    gradients = t.gradient(final_loss, watched)\n",
    "\n",
    "    for w, g in zip(watched, gradients):\n",
    "      w.assign_sub(g)\n",
    "\n",
    "    return final_loss\n",
    "  \n",
    "  @tf.function(input_signature=[tf.TensorSpec([None], tf.dtypes.string)])  \n",
    "  def get_encoder_output(self,sentences):\n",
    "        tokens,lookup_ids = self._tokens_to_lookup_ids(sentences)\n",
    "        sentence_embeddings = tf.nn.embedding_lookup(self._embeddings,\n",
    "                                                     lookup_ids)\n",
    "        encoder_output = self.model(sentence_embeddings)\n",
    "        return encoder_output\n",
    "    \n",
    "  @tf.function\n",
    "  def decode_greedy(self, sequence_length, first_word):\n",
    "    #initial_state = self._lstm_cell.get_initial_state(\n",
    "    #    dtype=tf.float32, batch_size=1)\n",
    "\n",
    "    sequence = [first_word]\n",
    "    current_word = first_word\n",
    "    current_id = tf.expand_dims(self._words_to_indices(current_word), 0)\n",
    "    #current_state = initial_state\n",
    "\n",
    "    for _ in range(sequence_length):\n",
    "      token_embeddings = tf.nn.embedding_lookup(self._embeddings, current_id)\n",
    "      token_embeddings = tf.expand_dims(token_embeddings,0)\n",
    "      #logits = self.model(tf.expand_dims(token_embeddings,0))\n",
    "      lstm_output = self.model(token_embeddings)\n",
    "      lstm_output = tf.reshape(lstm_output, [-1,self._state_size])\n",
    "      logits = self._logit_layer(lstm_output)\n",
    "      softmax = tf.nn.softmax(logits)\n",
    "\n",
    "      next_ids = tf.math.argmax(softmax, axis=1)\n",
    "      next_words = self._indices_to_words(next_ids)[0]\n",
    "      \n",
    "      current_id = next_ids\n",
    "      current_word = next_words\n",
    "      sequence.append(current_word)\n",
    "\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:414: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:414: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.7682512, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6652212, shape=(), dtype=float32)\n",
      "tf.Tensor(2.580261, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5078623, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4499564, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4088717, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3808382, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3592927, shape=(), dtype=float32)\n",
      "tf.Tensor(2.340607, shape=(), dtype=float32)\n",
      "tf.Tensor(2.323387, shape=(), dtype=float32)\n",
      "tf.Tensor(2.307026, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2912605, shape=(), dtype=float32)\n",
      "tf.Tensor(2.275981, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2611341, shape=(), dtype=float32)\n",
      "tf.Tensor(2.246682, shape=(), dtype=float32)\n",
      "tf.Tensor(2.23259, shape=(), dtype=float32)\n",
      "tf.Tensor(2.218824, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2053483, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1921287, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1791327, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1663296, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1536915, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1411924, shape=(), dtype=float32)\n",
      "tf.Tensor(2.128808, shape=(), dtype=float32)\n",
      "tf.Tensor(2.116517, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1042972, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0921278, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0799873, shape=(), dtype=float32)\n",
      "tf.Tensor(2.067854, shape=(), dtype=float32)\n",
      "tf.Tensor(2.055705, shape=(), dtype=float32)\n",
      "tf.Tensor(2.043516, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0312588, shape=(), dtype=float32)\n",
      "tf.Tensor(2.018904, shape=(), dtype=float32)\n",
      "tf.Tensor(2.006418, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9937619, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9808918, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9677583, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9543033, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9404602, shape=(), dtype=float32)\n",
      "tf.Tensor(1.926155, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9113015, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8958068, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8795705, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8624908, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8444725, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8254437, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8053681, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7842743, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7622548, shape=(), dtype=float32)\n",
      "tf.Tensor(1.739563, shape=(), dtype=float32)\n",
      "tf.Tensor(1.716896, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7015821, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7772498, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4363782, shape=(), dtype=float32)\n",
      "tf.Tensor(2.7556677, shape=(), dtype=float32)\n",
      "tf.Tensor(2.217289, shape=(), dtype=float32)\n",
      "tf.Tensor(1.722746, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6825687, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6565703, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6350919, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6262283, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6370759, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7091907, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7790986, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9487419, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7092582, shape=(), dtype=float32)\n",
      "tf.Tensor(1.754462, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6399007, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6895092, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5889499, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6304059, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5520211, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5874134, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5181193, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5491306, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4862224, shape=(), dtype=float32)\n",
      "tf.Tensor(1.512978, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4555725, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4782691, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4258884, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4445604, shape=(), dtype=float32)\n",
      "tf.Tensor(1.396832, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4114349, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3680996, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3785437, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3394202, shape=(), dtype=float32)\n",
      "tf.Tensor(1.345624, shape=(), dtype=float32)\n",
      "tf.Tensor(1.310559, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3124754, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2812835, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2789003, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2512993, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2446113, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2201396, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2090648, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1869292, shape=(), dtype=float32)\n",
      "tf.Tensor(1.171076, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1497748, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1277043, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1039577, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0709298, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0379623, shape=(), dtype=float32)\n",
      "tf.Tensor(0.98653316, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9531974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9155441, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9021328, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8800266, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8700599, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8523349, shape=(), dtype=float32)\n",
      "tf.Tensor(0.84553313, shape=(), dtype=float32)\n",
      "tf.Tensor(0.82949597, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8277023, shape=(), dtype=float32)\n",
      "tf.Tensor(0.81109387, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8161002, shape=(), dtype=float32)\n",
      "tf.Tensor(0.79505676, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8065469, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7784321, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7942143, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7611465, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7798197, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7444477, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7654736, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7287395, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7516106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.71402293, shape=(), dtype=float32)\n",
      "tf.Tensor(0.73818076, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70023286, shape=(), dtype=float32)\n",
      "tf.Tensor(0.72507566, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68729395, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7121834, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6751325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69941974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.66368026, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68675804, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65287477, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6742312, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6426592, shape=(), dtype=float32)\n",
      "tf.Tensor(0.66191214, shape=(), dtype=float32)\n",
      "tf.Tensor(0.63298345, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6498738, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6238045, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6381721, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6150997, shape=(), dtype=float32)\n",
      "tf.Tensor(0.62685513, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6068895, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61600065, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5992723, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6057581, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5924485, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59636223, shape=(), dtype=float32)\n",
      "tf.Tensor(0.586602, shape=(), dtype=float32)\n",
      "tf.Tensor(0.58794016, shape=(), dtype=float32)\n",
      "tf.Tensor(0.58148915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5800423, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5760941, shape=(), dtype=float32)\n",
      "tf.Tensor(0.57149804, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56907904, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5612276, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5597471, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54931974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5487255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5371759, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53765106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.52639, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5279963, shape=(), dtype=float32)\n",
      "tf.Tensor(0.51745564, shape=(), dtype=float32)\n",
      "tf.Tensor(0.51967806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50905794, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5095403, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49804336, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49268037, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4806117, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46648166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45246145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44056576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43622637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43387586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43185326, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4299936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4282606, shape=(), dtype=float32)\n",
      "tf.Tensor(0.426633, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42509654, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.42364016, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42225543, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42093563, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41967514, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41846943, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41731432, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41620648, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41514271, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41412032, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41313675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41218978, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41127717, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41039726, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40954807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40872803, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40793574, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40716973, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40642864, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"<S> hello there <E>\", \"<S> how are you doing today <E>\",\"<S> I am fine thank you <E>\",\n",
    "             \"<S> hello world <E>\", \"<S> who are you? <E>\"]\n",
    "vocab = [\n",
    "      \"<S>\", \"<E>\", \"hello\", \"there\", \"how\", \"are\", \"you\", \"doing\", \"today\",\"I\",\"am\",\"fine\",\"thank\",\"world\",\n",
    "    \"who\"\n",
    "  ]\n",
    "\n",
    "module = ULMFiTModule(vocab=vocab, emb_dim=10, buckets=1, state_size=128,n_layers=2)\n",
    "\n",
    "for _ in range(200):\n",
    "    _ = module.train(tf.constant(sentences))\n",
    "    print(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<S> you', b'you', b'<E>', b'you', b'<E>', b'you', b'<E>', b'you', b'<E>', b'you', b'<E>']\n"
     ]
    }
   ],
   "source": [
    " # We have to call this function explicitly if we want it exported, because it\n",
    "  # has no input_signature in the @tf.function decorator.\n",
    "decoded = module.decode_greedy(sequence_length=10, first_word=tf.constant(\"<S> you\"))\n",
    "_ = [d.numpy() for d in decoded]\n",
    "print(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = module.get_encoder_output(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 7, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(module,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.saved_model.load(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = b.decode_greedy(sequence_length=10,first_word=tf.constant(\"<S> Hello\"))\n",
    "_ = [d.numpy() for d in decoded]\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Head \n",
    "\n",
    "\n",
    "Classifier head takes in the final layer output of the languaage model and first gets the average pool and max pool of the \n",
    "final layer outputs, then passes the concatanation of last time steps hidden state, max pool results and average pool results through given number Dense-dropout-batchnormalization blocks. Finally it produces the classifier output probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageClassifier(Model):\n",
    "    def __init__(self,num_labels,dense_units=(128,128),dropouts=(0.1,0.1)):\n",
    "        super(LanguageClassifier,self).__init__()\n",
    "        self.dense_layers = [Dense(units,activation=\"relu\") for units in dense_units]\n",
    "        self.dropout_layers = [Dropout(p) for p in dropouts]\n",
    "        self.max_pool_layer = GlobalMaxPooling1D()\n",
    "        self.average_pool_layer = GlobalAveragePooling1D()\n",
    "        self.batchnorm_layer = BatchNormalization()\n",
    "        self.n_layers = len(self.dense_layers)\n",
    "        self.final_layer = Dense(num_labels,activation=\"sigmoid\")\n",
    "        \n",
    "    def __call__(self,encoder_output):\n",
    "        self.enc_out = encoder_output\n",
    "        last_h = self.enc_out[:,-1,:]\n",
    "        max_pool_output = self.max_pool_layer(self.enc_out)\n",
    "        average_pool_output = self.average_pool_layer(self.enc_out)\n",
    "        \n",
    "        output = concatenate([last_h,max_pool_output,average_pool_output])\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            output = self.dense_layers[i](output)\n",
    "            output = self.dropout_layers[i](output)\n",
    "            output = self.batchnorm_layer(output)\n",
    "        \n",
    "        final_output = self.final_layer(output)\n",
    "        return final_output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LanguageClassifier(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = classifier(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=51501, shape=(5, 1), dtype=float32, numpy=\n",
       "array([[0.5138441 ],\n",
       "       [0.5131132 ],\n",
       "       [0.5401385 ],\n",
       "       [0.51430434],\n",
       "       [0.50680435]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
